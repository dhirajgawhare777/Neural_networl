{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i5GrRCQjBT8L"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "tf.compat.v1.disable_eager_execution()\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "QYN6O51fVJ7x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('sonar.all-data.csv')"
      ],
      "metadata": {
        "id": "FFeY5zrVB3pD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.info()"
      ],
      "metadata": {
        "id": "IvwEuUMGCJvi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "id": "hV0XaWrdCL_o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Total Columns : \", len(data.columns))"
      ],
      "metadata": {
        "id": "OrqTr0oiCRqI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data[data.columns[60]].value_counts()"
      ],
      "metadata": {
        "id": "I76to8p7WKMZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = data[data.columns[0:60]].values\n",
        "y = data[data.columns[60]].values"
      ],
      "metadata": {
        "id": "nBaGhWlpWKpv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X.shape)"
      ],
      "metadata": {
        "id": "YYrkTbl2WQ-a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def one_hot_encode(labels):\n",
        "    n_labels = len(labels)\n",
        "    n_unique_labels = len(np.unique(labels))\n",
        "    one_hot_encode = np.zeros((n_labels,n_unique_labels))\n",
        "    one_hot_encode[np.arange(n_labels), labels] = 1\n",
        "    return one_hot_encode"
      ],
      "metadata": {
        "id": "efruvExDWRUo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = LabelEncoder()\n",
        "encoder.fit(y)\n",
        "y = encoder.transform(y)\n",
        "Y = one_hot_encode(y)"
      ],
      "metadata": {
        "id": "EPnqojQnWZu4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y[0]"
      ],
      "metadata": {
        "id": "vUyaWHFZWaT4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X,Y = shuffle (X, Y, random_state = 0)"
      ],
      "metadata": {
        "id": "MhrN0d7CWf4K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_x, test_x, train_y, test_y = train_test_split(X, Y, test_size = 0.20, random_state = 0)"
      ],
      "metadata": {
        "id": "BTPYYDfYWlQ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.2\n",
        "training_epochs = 500\n",
        "n_dim = X.shape[1]\n",
        "print(\"n_dim = \", n_dim)\n",
        "n_class = 2"
      ],
      "metadata": {
        "id": "fY17WZOUWnRR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cost_history = np.empty(shape=[1],dtype=float)"
      ],
      "metadata": {
        "id": "qEoQbdecWsYW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_hidden_1 = 60\n",
        "n_hidden_2 = 60\n",
        "n_hidden_3 = 60\n",
        "n_hidden_4 = 60"
      ],
      "metadata": {
        "id": "edSJhzMBWy0A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = tf.compat.v1.placeholder(tf.float32, [None, n_dim])\n",
        "W = tf.Variable(tf.zeros([n_dim, n_class]))\n",
        "b = tf.Variable(tf.zeros([n_class]))\n",
        "y_ = tf.compat.v1.placeholder(tf.float32, [None, n_class])"
      ],
      "metadata": {
        "id": "5oi_k_PUW4kh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def multilayer_perceptron(x, weights, biases):\n",
        "\n",
        "    # Hidden layer with RELU activationsd\n",
        "    layer_1 = tf.add(tf.matmul(x, weights['h1']), biases['b1'])\n",
        "    layer_1 = tf.nn.relu(layer_1)\n",
        "\n",
        "    # Hidden layer with sigmoid activation\n",
        "    layer_2 = tf.add(tf.matmul(layer_1, weights['h2']), biases['b2'])\n",
        "    layer_2 = tf.nn.relu(layer_2)\n",
        "\n",
        "    # Hidden layer with sigmoid activation\n",
        "    layer_3 = tf.add(tf.matmul(layer_2, weights['h3']), biases['b3'])\n",
        "    layer_3 = tf.nn.relu(layer_3)\n",
        "\n",
        "    # Hidden layer with RELU activation\n",
        "    layer_4 = tf.add(tf.matmul(layer_3, weights['h4']), biases['b4'])\n",
        "    layer_4 = tf.nn.sigmoid(layer_4)\n",
        "\n",
        "    # Output layer with linear activation\n",
        "    out_layer = tf.matmul(layer_4, weights['out']) + biases['out']\n",
        "    return out_layer\n",
        "\n",
        "# Define the weights for each layers"
      ],
      "metadata": {
        "id": "lPaqB5zrW5bJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the weights for each layers\n",
        "\n",
        "weights = {\n",
        "    'h1': tf.Variable(tf.compat.v1.truncated_normal([n_dim, n_hidden_1])),\n",
        "    'h2': tf.Variable(tf.compat.v1.truncated_normal([n_hidden_1, n_hidden_2])),\n",
        "    'h3': tf.Variable(tf.compat.v1.truncated_normal([n_hidden_2, n_hidden_3])),\n",
        "    'h4': tf.Variable(tf.compat.v1.truncated_normal([n_hidden_3, n_hidden_4])),\n",
        "    'out': tf.Variable(tf.compat.v1.truncated_normal([n_hidden_4, n_class]))\n",
        "}"
      ],
      "metadata": {
        "id": "z3TDiAdjYIlH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "biases = {\n",
        "    'b1': tf.Variable(tf.compat.v1.truncated_normal([n_hidden_1])),\n",
        "    'b2': tf.Variable(tf.compat.v1.truncated_normal([n_hidden_2])),\n",
        "    'b3': tf.Variable(tf.compat.v1.truncated_normal([n_hidden_3])),\n",
        "    'b4': tf.Variable(tf.compat.v1.truncated_normal([n_hidden_4])),\n",
        "    'out': tf.Variable(tf.compat.v1.truncated_normal([n_class]))\n",
        "}"
      ],
      "metadata": {
        "id": "HALJT2BIYOgT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "init = tf.compat.v1.global_variables_initializer()"
      ],
      "metadata": {
        "id": "E9G1R_ZRYmhG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = multilayer_perceptron(x, weights, biases)"
      ],
      "metadata": {
        "id": "9J1AwPZGYqqj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cost_function = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=y, labels=y_))\n",
        "training_step = tf.compat.v1.train.GradientDescentOptimizer(learning_rate).minimize(cost_function)"
      ],
      "metadata": {
        "id": "fF-8Nj7zYwmi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sess = tf.compat.v1.Session()\n",
        "sess.run(init)"
      ],
      "metadata": {
        "id": "Bi4k2a21Y1P-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mse_history = []\n",
        "accuracy_history = []"
      ],
      "metadata": {
        "id": "0xlz2C7IZG0F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(training_epochs):\n",
        "    sess.run(training_step, feed_dict = {x: train_x, y_: train_y})\n",
        "    cost = sess.run(cost_function, feed_dict={x: train_x, y_: train_y})\n",
        "    cost_history = np.append(cost_history, cost)\n",
        "    correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n",
        "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "    pred_y = sess.run(y, feed_dict = {x: test_x})\n",
        "    mse = tf.reduce_mean(tf.square(pred_y - test_y))\n",
        "    mse_ = sess.run(mse)\n",
        "    mse_history.append(mse_)\n",
        "    accuracy = (sess.run(accuracy, feed_dict={x: train_x, y_: train_y}))\n",
        "    accuracy_history.append(accuracy)\n",
        "\n",
        "    if epoch % 50 == 0:\n",
        "        print('epoch : ', epoch, ' ; ', 'cost: ', cost, \" ; MSE: \", mse_, \"- Train Accuracy: \", accuracy )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ZmrEf2YzanS",
        "outputId": "e3916d8b-d493-439c-ace7-8e5b4cc55f8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch :  150  ;  cost:  1.4088273  ; MSE:  4.971607517200296 - Train Accuracy:  0.54545456\n",
            "epoch :  200  ;  cost:  1.3552343  ; MSE:  6.15817169280856 - Train Accuracy:  0.58181816\n",
            "epoch :  250  ;  cost:  0.57314384  ; MSE:  2.7474274348986114 - Train Accuracy:  0.77575755\n",
            "epoch :  300  ;  cost:  0.43428013  ; MSE:  5.095224158775006 - Train Accuracy:  0.77575755\n",
            "epoch :  350  ;  cost:  0.27691722  ; MSE:  4.0257882057790795 - Train Accuracy:  0.8848485\n",
            "epoch :  400  ;  cost:  0.17262216  ; MSE:  4.449286378469919 - Train Accuracy:  0.95757574\n",
            "epoch :  450  ;  cost:  0.108565316  ; MSE:  5.5417108000166975 - Train Accuracy:  0.9757576\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(range(len(cost_history)), cost_history)\n",
        "plt.xlabel('Epochs ')\n",
        "plt.ylabel('Cost_History ')\n",
        "plt.title(\"Cost per Epoch Graph\")\n",
        "plt.xlim(0, training_epochs + 10)\n",
        "plt.ylim(0, np.max(cost_history))\n",
        "plt.rcParams['figure.figsize'] = [12, 5]\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "zmvSiux_zhkp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(range(len(accuracy_history)), accuracy_history)\n",
        "plt.xlabel('Epochs ')\n",
        "plt.ylabel('Accuracy_History ')\n",
        "plt.title(\"Cost per Epoch Graph\")\n",
        "plt.xlim(0, training_epochs + 10)\n",
        "plt.ylim(0.4, np.max(accuracy_history)+0.2)\n",
        "plt.rcParams['figure.figsize'] = [12, 5]\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hiIIZqFxzsuS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "print(\"Test Accuracy: \", (sess.run(accuracy, feed_dict={x: test_x, y_: test_y})))"
      ],
      "metadata": {
        "id": "rkRRdyahztc9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_y = sess.run(y, feed_dict={x: test_x})\n",
        "mse = tf.reduce_mean(tf.square(pred_y - test_y))\n",
        "print(\"MSE: %.4f\" % sess.run(mse))"
      ],
      "metadata": {
        "id": "o6IL-2Zr0LLq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DTLRLv6N0l1C"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}